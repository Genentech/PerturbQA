{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7874f96-dcd0-4619-a92b-2da7be7b75ef",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Parsing results for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba655dbe-89f0-490e-8ecb-0ec58a7d5b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338fb536-69d5-4c3b-98c7-cdb0a520aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from perturbqa import load_de, auc_per_gene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b5b869-ba26-4ab7-b8b9-5c05f4fa3569",
   "metadata": {},
   "source": [
    "## Evaluating individual predictions\n",
    "\n",
    "Example of parsing individual files in `results.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f596e1-ae06-49ca-8cce-61b910d79c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_de(\"k562\")[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95d82912-cb23-47ac-84c5-0d96dd9d0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/gears/k562.pkl\", \"rb\") as f:\n",
    "    preds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb7ff469-ad2e-4982-b2be-1605fc10b088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['key', 'de_pred', 'de_true', 'dir_pred', 'dir_true'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "006f958f-c825-471a-8867-6316d3ea3440",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"key\" in preds:\n",
    "    de_key = preds[\"key\"]\n",
    "else:\n",
    "    de_key = preds[\"de_key\"]\n",
    "de_pred = preds[\"de_pred\"]\n",
    "de_true = preds[\"de_true\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec5b780d-86ca-46c7-83db-60813ac8a959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5451993240694406"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_per_gene(de_key, de_pred, de_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34c02d2f-e18c-4f74-8de0-425779d679cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5451993240694406"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_per_gene(de_key, de_pred, [item[\"label\"] for item in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31101c7-acf1-4461-83bf-4cd44e6c4318",
   "metadata": {},
   "source": [
    "## Summary results\n",
    "\n",
    "Example code for producing Table 1 (without uncertainties)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75fc8769-2327-46dd-a7fa-76dff1484112",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"../results/summary.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b28b773c-dea9-472f-bd1e-fbb1cd1383d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c172d4bc-f5eb-4e6f-a299-b82f7219d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_row(mean, is_best):\n",
    "    if is_best:\n",
    "        return f\"$\\\\textbf{{{mean:.2f}}}$\"\n",
    "    return f\"${mean:.2f}$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63f1c8b0-f709-4436-aadf-c7fc6ec91d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"MLP\", \"GAT\", \"GEARS\",\n",
    "     None,\n",
    "     \"GenePT-Gene\",\n",
    "     \"GenePT-Protein\",\n",
    "     \"LLM-NoCoT\",\n",
    "     \"LLM-0-Shot\",\n",
    "     \"LLM-Prompt\",\n",
    "     None,\n",
    "     \"LLM-FewShot\",\n",
    "]\n",
    "latex_names = [\n",
    "    \"\\\\textsc{Mlp}\", \"\\\\textsc{Gat}\", \"\\\\textsc{Gears}\",\n",
    "    None,\n",
    "    \"\\\\textsc{GenePt-Gene}\", \"\\\\textsc{GenePt-Prot}\",\n",
    "    \"\\\\textsc{Llm} (No CoT)\",\n",
    "    \"\\\\textsc{Llm} (No retrieval)\",\n",
    "    \"Retrieval (No \\\\textsc{Llm})\",\n",
    "    None,\n",
    "    \"\\\\ours{}\",\n",
    "]\n",
    "tasks = [\"de\", \"dir\"]\n",
    "datasets = [\"k562_gw\", \"rpe1_essential\", \"hepg2\", \"jurkat\", \"k562_gw_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c298a7b-1c85-4306-ac88-75c2762ed168",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_results\n",
    "\n",
    "model_metrics = {}\n",
    "best_metrics = {}\n",
    "for dataset in datasets:\n",
    "    for task in tasks:\n",
    "        means = []\n",
    "        for model in names:\n",
    "            if model is None:\n",
    "                continue\n",
    "            metric_col = df[(df[\"dataset\"] == dataset) &\n",
    "                            (df[\"task\"] == task) &\n",
    "                            (df[\"model\"] == model)][\"AUC\"]\n",
    "            mean = metric_col.mean().item()\n",
    "            model_metrics[(dataset, task, model)] = mean\n",
    "            means.append(mean)\n",
    "        if len(means) == 0:  # shouldn't ever be called\n",
    "            print(task, model)\n",
    "        best_metrics[(dataset, task)] = max(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b87cbfa3-9929-486d-a4ca-6a19a692df0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&\\textsc{Mlp}& $0.48$& $0.51$& $0.51$& $0.49$& $0.49$\\\\\n",
      "&\\textsc{Gat}& $0.53$& $0.55$& $0.58$& $0.51$& $0.55$\\\\\n",
      "&\\textsc{Gears}& $0.55$& $0.49$& $0.48$& $0.51$& $0.50$\\\\\n",
      "\\cmidrule(l{\\tabcolsep}){1-7}\n",
      "&\\textsc{GenePt-Gene}& $0.57$& $0.55$& $0.56$& $0.55$& $0.58$\\\\\n",
      "&\\textsc{GenePt-Prot}& $0.59$& $0.56$& $0.54$& $0.55$& $0.59$\\\\\n",
      "&\\textsc{Llm} (No CoT)& $0.52$& $0.52$& $0.51$& $0.52$& $0.51$\\\\\n",
      "&\\textsc{Llm} (No retrieval)& $0.52$& $0.48$& $0.49$& $0.49$& $0.50$\\\\\n",
      "&Retrieval (No \\textsc{Llm})& $0.58$& $\\textbf{0.59}$& $0.56$& $0.56$& $\\textbf{0.66}$\\\\\n",
      "\\cmidrule(l{\\tabcolsep}){1-7}\n",
      "&\\ours{}& $\\textbf{0.62}$& $\\textbf{0.59}$& $\\textbf{0.62}$& $\\textbf{0.59}$& $0.62$\\\\\n",
      "\\midrule\\midrule\n",
      "&\\textsc{Mlp}& $0.53$& $0.51$& $0.49$& $0.45$& $0.48$\\\\\n",
      "&\\textsc{Gat}& $0.59$& $0.60$& $0.63$& $0.58$& $0.51$\\\\\n",
      "&\\textsc{Gears}& $0.67$& $0.61$& $0.52$& $0.52$& $\\textbf{0.70}$\\\\\n",
      "\\cmidrule(l{\\tabcolsep}){1-7}\n",
      "&\\textsc{GenePt-Gene}& $0.49$& $0.61$& $0.61$& $0.57$& $0.54$\\\\\n",
      "&\\textsc{GenePt-Prot}& $0.55$& $0.61$& $0.55$& $0.60$& $0.57$\\\\\n",
      "&\\textsc{Llm} (No CoT)& $0.50$& $0.49$& $0.49$& $0.50$& $0.50$\\\\\n",
      "&\\textsc{Llm} (No retrieval)& $0.50$& $0.52$& $0.53$& $0.54$& $0.49$\\\\\n",
      "&Retrieval (No \\textsc{Llm})& $\\textbf{0.69}$& $0.63$& $0.64$& $0.61$& $0.66$\\\\\n",
      "\\cmidrule(l{\\tabcolsep}){1-7}\n",
      "&\\ours{}& $0.64$& $\\textbf{0.64}$& $\\textbf{0.66}$& $\\textbf{0.67}$& $\\textbf{0.70}$\\\\\n",
      "\\midrule\\midrule\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    for i, (model, latex_name) in enumerate(zip(names, latex_names)):\n",
    "        if model is None:\n",
    "            print(\"\\\\cmidrule(l{\\\\tabcolsep}){1-7}\")\n",
    "            continue\n",
    "        # print num nodes on first line\n",
    "        line = \"&\" + latex_name\n",
    "        for dataset in datasets:\n",
    "            mean = model_metrics[(dataset, task, model)]\n",
    "            is_best = np.isclose(mean, best_metrics[(dataset, task)], atol=0.005)\n",
    "            line += f\"& {format_row(mean, is_best)}\"\n",
    "        line += \"\\\\\\\\\"\n",
    "        print(line)\n",
    "    print(\"\\\\midrule\\\\midrule\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
